---
title: "Supercharge your LLM performance with Amazon SageMaker Large Model Inference container v15"
date: 2025-04-22T17:28:40+00:00
link: https://aws.amazon.com/blogs/machine-learning/supercharge-your-llm-performance-with-amazon-sagemaker-large-model-inference-container-v15/
showShare: false
showReadTime: false
thumbnail: images/aws.png
tags: ["aws.amazon.com/blogs/machine-learning"]
---
Today, weâ€™re excited to announce the launch of Amazon SageMaker Large Model Inference (LMI) container v15, powered by vLLM 0.8.4 with support for the vLLM V1 engine. This release introduces significant performance improvements, expanded model compatibility with multimodality (that is, the ability to understand and analyze text-to-text, images-to-text, and text-to-images data), and provides built-in integration with vLLM to help you seamlessly deploy and serve large language models (LLMs) with the highest performance at scale.

- Link to article: https://aws.amazon.com/blogs/machine-learning/supercharge-your-llm-performance-with-amazon-sagemaker-large-model-inference-container-v15/