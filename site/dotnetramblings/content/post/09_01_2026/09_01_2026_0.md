---
title: "Accelerating LLM inference with post-training weight and activation using AWQ and GPTQ on Amazon SageMaker AI"
date: 2026-01-09T18:09:22+00:00
link: https://aws.amazon.com/blogs/machine-learning/accelerating-llm-inference-with-post-training-weight-and-activation-using-awq-and-gptq-on-amazon-sagemaker-ai/
showShare: false
showReadTime: false
thumbnail: images/aws.png
tags: ["aws.amazon.com/blogs/machine-learning"]
---
Quantized models can be seamlessly deployed on Amazon SageMaker AI using a few lines of code. In this post, we explore why quantization mattersâ€”how it enables lower-cost inference, supports deployment on resource-constrained hardware, and reduces both the financial and environmental impact of modern LLMs, while preserving most of their original performance. We also take a deep dive into the principles behind PTQ and demonstrate how to quantize the model of your choice and deploy it on Amazon SageMaker.

- Link to article: https://aws.amazon.com/blogs/machine-learning/accelerating-llm-inference-with-post-training-weight-and-activation-using-awq-and-gptq-on-amazon-sagemaker-ai/